{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f01425",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Flight-Data-Preprocessing\" data-toc-modified-id=\"Flight-Data-Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Flight Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Importing-Libraries\" data-toc-modified-id=\"1.-Importing-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1. Importing Libraries</a></span></li><li><span><a href=\"#2.-Data-Loading-and-Initial-Feature-Selection\" data-toc-modified-id=\"2.-Data-Loading-and-Initial-Feature-Selection-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>2. Data Loading and Initial Feature Selection</a></span></li><li><span><a href=\"#3.-Data-Cleaning-and-Preprocessing\" data-toc-modified-id=\"3.-Data-Cleaning-and-Preprocessing-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>3. Data Cleaning and Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Filtering-and-Renaming-Features\" data-toc-modified-id=\"3.1-Filtering-and-Renaming-Features-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>3.1 Filtering and Renaming Features</a></span></li><li><span><a href=\"#3.2-Handling-Missing-Values\" data-toc-modified-id=\"3.2-Handling-Missing-Values-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>3.2 Handling Missing Values</a></span></li><li><span><a href=\"#3.3-Removing-Duplicate-Rows\" data-toc-modified-id=\"3.3-Removing-Duplicate-Rows-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>3.3 Removing Duplicate Rows</a></span></li><li><span><a href=\"#3.4-Handling-Missing-Tail-Numbers\" data-toc-modified-id=\"3.4-Handling-Missing-Tail-Numbers-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>3.4 Handling Missing Tail Numbers</a></span></li><li><span><a href=\"#3.5-Handling-Diverted-Flights\" data-toc-modified-id=\"3.5-Handling-Diverted-Flights-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>3.5 Handling Diverted Flights</a></span></li><li><span><a href=\"#3.6-Reset-Index-After-Removing-Rows\" data-toc-modified-id=\"3.6-Reset-Index-After-Removing-Rows-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;</span>3.6 Reset Index After Removing Rows</a></span></li></ul></li><li><span><a href=\"#4.-Airport-Data-Integration\" data-toc-modified-id=\"4.-Airport-Data-Integration-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>4. Airport Data Integration</a></span></li><li><span><a href=\"#5.-Time-Related-Data-Processing\" data-toc-modified-id=\"5.-Time-Related-Data-Processing-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>5. Time-Related Data Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-Converting-Flight-Dates-and-Times\" data-toc-modified-id=\"5.1-Converting-Flight-Dates-and-Times-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>5.1 Converting Flight Dates and Times</a></span></li><li><span><a href=\"#5.2-Calculating-Departure-Times\" data-toc-modified-id=\"5.2-Calculating-Departure-Times-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>5.2 Calculating Departure Times</a></span></li><li><span><a href=\"#5.3-Handling-Diverted-Flights\" data-toc-modified-id=\"5.3-Handling-Diverted-Flights-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>5.3 Handling Diverted Flights</a></span></li><li><span><a href=\"#5.4-Calculating-Arrival-Times\" data-toc-modified-id=\"5.4-Calculating-Arrival-Times-1.5.4\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span>5.4 Calculating Arrival Times</a></span></li><li><span><a href=\"#5.5-Converting-to-Destination-Timezone\" data-toc-modified-id=\"5.5-Converting-to-Destination-Timezone-1.5.5\"><span class=\"toc-item-num\">1.5.5&nbsp;&nbsp;</span>5.5 Converting to Destination Timezone</a></span></li><li><span><a href=\"#5.6-Calculating-Arrival-Delays\" data-toc-modified-id=\"5.6-Calculating-Arrival-Delays-1.5.6\"><span class=\"toc-item-num\">1.5.6&nbsp;&nbsp;</span>5.6 Calculating Arrival Delays</a></span></li><li><span><a href=\"#5.7-Handling-Incorrect-Data\" data-toc-modified-id=\"5.7-Handling-Incorrect-Data-1.5.7\"><span class=\"toc-item-num\">1.5.7&nbsp;&nbsp;</span>5.7 Handling Incorrect Data</a></span></li><li><span><a href=\"#5.8-Converting-All-Times-to-UTC\" data-toc-modified-id=\"5.8-Converting-All-Times-to-UTC-1.5.8\"><span class=\"toc-item-num\">1.5.8&nbsp;&nbsp;</span>5.8 Converting All Times to UTC</a></span></li></ul></li><li><span><a href=\"#6.-Final-Data-Transformations\" data-toc-modified-id=\"6.-Final-Data-Transformations-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>6. Final Data Transformations</a></span></li><li><span><a href=\"#7.-Final-Dataset-and-Export\" data-toc-modified-id=\"7.-Final-Dataset-and-Export-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>7. Final Dataset and Export</a></span></li><li><span><a href=\"#8.-Data-Exploration-and-Validation-(Optional)\" data-toc-modified-id=\"8.-Data-Exploration-and-Validation-(Optional)-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>8. Data Exploration and Validation (Optional)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d388fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    \n",
    "# Flight Data Preprocessing\n",
    "\n",
    "This notebook performs comprehensive data preprocessing on flight data from BTS (Bureau of Transportation Statistics) for flights in New York during January 2023. The preprocessing includes data cleaning, feature selection, time zone handling, and data transformation to prepare the dataset for analysis.\n",
    "\n",
    "## 1. Importing Libraries\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "```\n",
    "\n",
    "## 2. Data Loading and Initial Feature Selection\n",
    "\n",
    "```python\n",
    "# Read feature's old and new names from documentation\n",
    "path_features = './data/raw_data/Documentation.xlsx'\n",
    "all_features_df = pd.read_excel(path_features, usecols=[\"SYS_FIELD_NAME\", \"NEW_NAME\", \"FIELD_DESC\"])\n",
    "\n",
    "# Drop unwanted features (where \"NEW_NAME\" is blank)\n",
    "considered_features_df = all_features_df[all_features_df[\"NEW_NAME\"].notnull()]\n",
    "list_considered_features = list(considered_features_df[\"SYS_FIELD_NAME\"])\n",
    "list_new_names = list(considered_features_df[\"NEW_NAME\"].apply(\n",
    "    lambda x: x.encode('utf-8').decode('unicode_escape') if isinstance(x, str) else x))\n",
    "\n",
    "# Read raw flight data\n",
    "path_data = r'./data/raw_data/BTS_NewYork_Jan23.csv'\n",
    "raw_data_df = pd.read_csv(path_data)\n",
    "print(\"=\"*75, \"\\nInitial shape --> \", raw_data_df.shape)\n",
    "```\n",
    "\n",
    "## 3. Data Cleaning and Preprocessing\n",
    "\n",
    "### 3.1 Filtering and Renaming Features\n",
    "\n",
    "```python\n",
    "# Filter raw data to keep only considered features\n",
    "print(\"=\"*75, \"\\nRemoving unwanted features:\")\n",
    "cleaned_df = raw_data_df[list_considered_features].copy()\n",
    "\n",
    "# Rename features according to the documentation\n",
    "cleaned_df.columns = list_new_names\n",
    "print(\"Shape --> \", cleaned_df.shape)\n",
    "```\n",
    "\n",
    "### 3.2 Handling Missing Values\n",
    "\n",
    "```python\n",
    "# Check missing values in each column\n",
    "nans = pd.DataFrame(cleaned_df.notnull().sum(), columns=['Values'])\n",
    "nans['NaNs'] = len(cleaned_df) - nans['Values']\n",
    "nans['NaNs (%)'] = nans['NaNs'] * 100 / len(cleaned_df)\n",
    "print(\"=\"*75, \"\\nMissing values in each column: \\n\\n\", nans)\n",
    "\n",
    "# Drop completely empty columns\n",
    "empty_columns = list(nans[nans['NaNs'] == len(cleaned_df)].index)\n",
    "print(\"=\"*75, \"\\nDeleting completely empty columns:\\t\", empty_columns)\n",
    "cleaned_df.drop(empty_columns, axis=1, inplace=True)\n",
    "print(\"Shape --> \", cleaned_df.shape)\n",
    "```\n",
    "\n",
    "### 3.3 Removing Duplicate Rows\n",
    "\n",
    "```python\n",
    "# Drop duplicated rows\n",
    "print(\"=\"*75, \"\\nDeleting [{}] duplicated rows.\".format(cleaned_df[cleaned_df.duplicated()].shape[0]))\n",
    "cleaned_df.drop_duplicates(inplace=True)\n",
    "print(\"Shape --> \", cleaned_df.shape)\n",
    "```\n",
    "\n",
    "### 3.4 Handling Missing Tail Numbers\n",
    "\n",
    "```python\n",
    "# Remove flights with unknown tail numbers\n",
    "rows_to_remove = cleaned_df[cleaned_df[\"Tail Number\"].isna()]\n",
    "print(\"=\"*75, \"\\nDeleting [{}] flights with unknown tail number.\".format(rows_to_remove.shape[0]))\n",
    "cleaned_df.drop(rows_to_remove.index, axis=0, inplace=True)\n",
    "print(\"Shape --> \", cleaned_df.shape)\n",
    "```\n",
    "\n",
    "### 3.5 Handling Diverted Flights\n",
    "\n",
    "```python\n",
    "# Analyze diverted flights\n",
    "num_diverted = cleaned_df[cleaned_df[\"Diversion Label\"]==1].shape[0]\n",
    "reached_sched_dest = cleaned_df[(cleaned_df[\"Diversion Label\"]==1) & \n",
    "                               (cleaned_df[\"Diversion Reached Destination\"]==1)].shape[0]\n",
    "not_reached_sched_dest = cleaned_df[(cleaned_df[\"Diversion Label\"]==1) & \n",
    "                                  (cleaned_df[\"Diversion Reached Destination\"]==0)].shape[0]\n",
    "\n",
    "print(\"=\"*75, \"\\nTotal number of diverted flights = {}.\".format(num_diverted))\n",
    "print(\"--> {} flights reached the scheduled destination.\".format(reached_sched_dest))\n",
    "print(\"--> {} flights did not reach the scheduled destination.\".format(not_reached_sched_dest))\n",
    "\n",
    "# Remove diverted flights that did not reach the scheduled destination\n",
    "rows_to_remove = cleaned_df[cleaned_df[\"Diversion Reached Destination\"]==0]\n",
    "print(\"Deleting [{}] diverted flights that did not reach the scheduled destination.\".format(rows_to_remove.shape[0]))\n",
    "cleaned_df.drop(rows_to_remove.index, axis=0, inplace=True)\n",
    "print(\"Shape --> \", cleaned_df.shape)\n",
    "```\n",
    "\n",
    "### 3.6 Reset Index After Removing Rows\n",
    "\n",
    "```python\n",
    "# Reset DataFrame indices after dropping rows\n",
    "print(\"=\"*75, \"\\nResetting DataFrame indices.\")\n",
    "cleaned_df.reset_index(drop=True, inplace=True)\n",
    "print(\"=\"*75)\n",
    "```\n",
    "\n",
    "## 4. Airport Data Integration\n",
    "\n",
    "```python\n",
    "# Load airport data\n",
    "airportsFile = 'data/raw_data/airports.dat'\n",
    "airports_df = pd.read_csv(\n",
    "    airportsFile, header=None, encoding=\"utf-8\",\n",
    "    names=[\"AirportID\", \"Name\", \"City\", \"Country\", \"IATA\", \"ICAO\", \"Latitude\",\n",
    "           \"Longitude\", \"Altitude\", \"Timezone\", \"DST\", \"Tz database\", \"Type\", \"Source\"]\n",
    ")\n",
    "\n",
    "# Merge with origin airport data\n",
    "merged_df = cleaned_df.merge(airports_df[[\"IATA\", \"ICAO\", \"Tz database\"]], \n",
    "                          left_on=\"IATA Origin Airport\", right_on=\"IATA\", \n",
    "                          how=\"left\").drop(columns=[\"IATA\"])\n",
    "merged_df.rename(columns={\"ICAO\": \"ICAO Origin Airport\", \n",
    "                          \"Tz database\": \"TZ Origin Airport\"}, inplace=True)\n",
    "\n",
    "# Merge with destination airport data\n",
    "merged_df = merged_df.merge(airports_df[[\"IATA\", \"ICAO\", \"Tz database\"]], \n",
    "                            left_on=\"IATA Destination Airport\", right_on=\"IATA\", \n",
    "                            how=\"left\").drop(columns=[\"IATA\"])\n",
    "merged_df.rename(columns={\"ICAO\": \"ICAO Destination Airport\", \n",
    "                          \"Tz database\": \"TZ Destination Airport\"}, inplace=True)\n",
    "\n",
    "# Reorganize columns for better readability\n",
    "merged_df.insert(7, \"ICAO Origin Airport\", merged_df.pop(\"ICAO Origin Airport\"))\n",
    "merged_df.insert(8, \"TZ Origin Airport\", merged_df.pop(\"TZ Origin Airport\"))\n",
    "merged_df.insert(14, \"ICAO Destination Airport\", merged_df.pop(\"ICAO Destination Airport\"))\n",
    "merged_df.insert(15, \"TZ Destination Airport\", merged_df.pop(\"TZ Destination Airport\"))\n",
    "\n",
    "# Replace IATA with ICAO codes for airports and add timezone information\n",
    "cleaned_df[\"IATA Origin Airport\"] = merged_df[\"ICAO Origin Airport\"]\n",
    "cleaned_df[\"IATA Destination Airport\"] = merged_df[\"ICAO Destination Airport\"]\n",
    "cleaned_df.rename(columns={\"IATA Origin Airport\": \"ICAO Origin Airport\",\n",
    "                        \"IATA Destination Airport\": \"ICAO Destination Airport\"},\n",
    "              inplace=True)\n",
    "cleaned_df.insert(7, \"TZ Origin Airport\", merged_df[\"TZ Origin Airport\"])\n",
    "cleaned_df.insert(13, \"TZ Destination Airport\", merged_df[\"TZ Destination Airport\"])\n",
    "```\n",
    "\n",
    "## 5. Time-Related Data Processing\n",
    "\n",
    "```python\n",
    "# Create a working copy of the cleaned dataframe\n",
    "df = cleaned_df.copy()\n",
    "\n",
    "# Function to convert integer time (HHMM) to time object (HH:MM)\n",
    "def convert_to_time(x):\n",
    "    \"\"\"\n",
    "    Convert integer time format (HHMM) to time object (HH:MM)\n",
    "    Handles special cases like 2400 and skips invalid values\n",
    "    \"\"\"\n",
    "    if pd.notna(x):     # Skip NaN\n",
    "        try:\n",
    "            x = int(x)  # Convert to an integer\n",
    "            if x == 2400:\n",
    "                return pd.Timestamp(\"00:00\").time()  # Handle the special case of 2400 as 00:00\n",
    "            # Convert to datetime, errors=\"coerce\" ensures invalid formats become NaT\n",
    "            time_val = pd.to_datetime(str(int(x)).zfill(4), format=\"%H%M\", errors=\"coerce\")\n",
    "            # Only extract time from datetime if the value is valid\n",
    "            if pd.notna(time_val): \n",
    "                return time_val.time()\n",
    "        except:\n",
    "            return np.nan  # In case of any unexpected errors\n",
    "    return np.nan  # Return NaN for invalid cases\n",
    "```\n",
    "\n",
    "### 5.1 Converting Flight Dates and Times\n",
    "\n",
    "```python\n",
    "# Convert \"Flight Date\" from string to datetime\n",
    "df[\"Flight Date\"] = pd.to_datetime(df[\"Flight Date\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Process \"Scheduled Departure Time\"\n",
    "# 1. Convert to time object\n",
    "df[\"Scheduled Departure Time\"] = df[\"Scheduled Departure Time\"].apply(convert_to_time)\n",
    "# 2. Combine with flight date\n",
    "df[\"Scheduled Departure Time\"] = df.apply(\n",
    "    lambda x: pd.Timestamp.combine(x[\"Flight Date\"], x[\"Scheduled Departure Time\"]) \n",
    "    if pd.notna(x[\"Scheduled Departure Time\"]) else np.nan, axis=1\n",
    ")\n",
    "# 3. Make timezone-aware based on origin airport\n",
    "df[\"Scheduled Departure Time\"] = df.apply(\n",
    "    lambda x: x[\"Scheduled Departure Time\"].tz_localize(x[\"TZ Origin Airport\"]) \n",
    "    if pd.notna(x[\"Scheduled Departure Time\"]) else np.nan, axis=1\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.2 Calculating Departure Times\n",
    "\n",
    "```python\n",
    "# Calculate \"Actual Departure Time\" = \"Scheduled Departure Time\" + \"Departure ΔT (min)\"\n",
    "df[\"Actual Departure Time\"] = df.apply(\n",
    "    lambda x: x[\"Scheduled Departure Time\"] + pd.to_timedelta(x[\"Departure ΔT (min)\"], unit='m') \n",
    "    if pd.notna(x[\"Scheduled Departure Time\"]) and pd.notna(x[\"Departure ΔT (min)\"]) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# Calculate \"Wheels Off Time\" = \"Actual Departure Time\" + \"Taxi Out Time (min)\"\n",
    "df[\"Wheels Off Time\"] = df.apply(\n",
    "    lambda x: x[\"Actual Departure Time\"] + pd.to_timedelta(x[\"Taxi Out Time (min)\"], unit='m') \n",
    "    if pd.notna(x[\"Actual Departure Time\"]) and pd.notna(x[\"Taxi Out Time (min)\"]) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.3 Handling Diverted Flights\n",
    "\n",
    "```python\n",
    "# Populate \"Actual Elapsed Time (min)\" & \"Air Time (min)\" for diverted flights\n",
    "# Apply updates only where Diversion Label == 1\n",
    "df.loc[df[\"Diversion Label\"] == 1, \"Actual Elapsed Time (min)\"] = df[\"Diversion Actual Elapsed Time (min)\"]\n",
    "\n",
    "df.loc[df[\"Diversion Label\"] == 1, \"Air Time (min)\"] = (\n",
    "    df[\"Diversion Actual Elapsed Time (min)\"] \n",
    "    - df[\"Taxi In Time (min)\"] \n",
    "    - df[\"Taxi Out Time (min)\"]\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.4 Calculating Arrival Times\n",
    "\n",
    "```python\n",
    "# Calculate \"Wheels On Time\" = \"Wheels Off Time\" + \"Air Time (min)\"\n",
    "df[\"Wheels On Time\"] = df.apply(\n",
    "    lambda x: x[\"Wheels Off Time\"] + pd.to_timedelta(x[\"Air Time (min)\"], unit='m') \n",
    "    if pd.notna(x[\"Wheels Off Time\"]) and pd.notna(x[\"Air Time (min)\"]) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# Calculate \"Scheduled Arrival Time\" = \"Scheduled Departure Time\" + \"Scheduled Elapsed Time (min)\"\n",
    "df[\"Scheduled Arrival Time\"] = df.apply(\n",
    "    lambda x: x[\"Scheduled Departure Time\"] + pd.to_timedelta(x[\"Scheduled Elapsed Time (min)\"], unit='m') \n",
    "    if pd.notna(x[\"Scheduled Departure Time\"]) and pd.notna(x[\"Scheduled Elapsed Time (min)\"]) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# Calculate \"Actual Arrival Time\" = \"Actual Departure Time\" + \"Actual Elapsed Time (min)\"\n",
    "df[\"Actual Arrival Time\"] = df.apply(\n",
    "    lambda x: x[\"Actual Departure Time\"] + pd.to_timedelta(x[\"Actual Elapsed Time (min)\"], unit='m') \n",
    "    if pd.notna(x[\"Actual Departure Time\"]) and pd.notna(x[\"Actual Elapsed Time (min)\"]) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.5 Converting to Destination Timezone\n",
    "\n",
    "```python\n",
    "# Convert times from origin to destination timezone\n",
    "df[\"Wheels On Time\"] = df.apply(\n",
    "    lambda x: x[\"Wheels On Time\"].tz_convert(x[\"TZ Destination Airport\"]) \n",
    "    if pd.notna(x[\"Wheels On Time\"]) else np.nan, axis=1\n",
    ")\n",
    "df[\"Scheduled Arrival Time\"] = df.apply(\n",
    "    lambda x: x[\"Scheduled Arrival Time\"].tz_convert(x[\"TZ Destination Airport\"]) \n",
    "    if pd.notna(x[\"Scheduled Arrival Time\"]) else np.nan, axis=1\n",
    ")\n",
    "df[\"Actual Arrival Time\"] = df.apply(\n",
    "    lambda x: x[\"Actual Arrival Time\"].tz_convert(x[\"TZ Destination Airport\"]) \n",
    "    if pd.notna(x[\"Actual Arrival Time\"]) else np.nan, axis=1\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.6 Calculating Arrival Delays\n",
    "\n",
    "```python\n",
    "# Calculate \"Arrival ΔT (min)\" = \"Actual Arrival Time\" - \"Scheduled Arrival Time\"\n",
    "df[\"Arrival ΔT (min)\"] = df.apply(\n",
    "    lambda x: (x[\"Actual Arrival Time\"] - x[\"Scheduled Arrival Time\"]).total_seconds() / 60 \n",
    "    if pd.notna(x[\"Actual Arrival Time\"]) and pd.notna(x[\"Scheduled Arrival Time\"]) \n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# Create \"Arrival Delay Label\" (1 if delay >= 15 min, 0 otherwise, NaN when \"Arrival ΔT (min)\" = NaN)\n",
    "df[\"Arrival Delay Label\"] = df[\"Arrival ΔT (min)\"].apply(\n",
    "    lambda x: 1.0 if pd.notna(x) and x >= 15 else (0.0 if pd.notna(x) else np.nan)\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.7 Handling Incorrect Data\n",
    "\n",
    "```python\n",
    "# Remove flights with inconsistent time data\n",
    "# 1. Mask out rows of diverted & cancelled flights (as by default \"Arrival ΔT (min)\" = NaN)\n",
    "valid_rows = ~((df[\"Diversion Label\"]==1) | (df[\"Cancellation Label\"]==1))\n",
    "\n",
    "# 2. Identify mismatches only for valid rows\n",
    "mismatched_rows = ((df[\"Arrival ΔT (min)\"][valid_rows] != cleaned_df[\"Arrival ΔT (min)\"][valid_rows]))\n",
    "mismatched_indices = df.index[valid_rows][mismatched_rows].tolist()\n",
    "\n",
    "# 3. Delete rows with wrong \"Arrival ΔT (min)\"\n",
    "print(\"=\"*75, \"\\nDeleting [{}] flights with wrong \\\"Scheduled Arrival Time\\\" or \\\"Scheduled Elapsed Time (min)\\\".\".format(len(mismatched_indices)))\n",
    "print(\"Shape before --> \", df.shape)\n",
    "df.drop(mismatched_indices, axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Shape after --> \", df.shape)\n",
    "print(\"=\"*75)\n",
    "```\n",
    "\n",
    "### 5.8 Converting All Times to UTC\n",
    "\n",
    "```python\n",
    "# Convert all times to UTC for consistency\n",
    "times_to_utc = [\"Scheduled Departure Time\", \"Actual Departure Time\", \n",
    "                \"Wheels Off Time\", \"Wheels On Time\",\n",
    "                \"Scheduled Arrival Time\", \"Actual Arrival Time\"]\n",
    "for t in times_to_utc:\n",
    "    df[\"{} UTC\".format(t)] = df[t].apply(lambda x: x.astimezone(pytz.UTC) if pd.notna(x) else np.nan)\n",
    "```\n",
    "\n",
    "## 6. Final Data Transformations\n",
    "\n",
    "```python\n",
    "# Remove \"Flight Date\" column (no longer needed)\n",
    "df.drop(\"Flight Date\", axis=1, inplace=True)\n",
    "\n",
    "# Update \"Quarter\" and \"Day of Week\" based on \"Scheduled Departure Time UTC\"\n",
    "df[\"Quarter\"] = df[\"Scheduled Departure Time UTC\"].dt.quarter\n",
    "df[\"Day of Week\"] = df[\"Scheduled Departure Time UTC\"].dt.weekday + 1  # Monday=1, Sunday=7\n",
    "\n",
    "# Convert object columns to string type (preserving NaNs)\n",
    "cols_to_string = [\"Unique Carrier Code\", \"Tail Number\", \"Div1 Tail Number\", \"ICAO Origin Airport\", \n",
    "                  \"Origin City\", \"Origin State Code\", \"Origin State Name\", \n",
    "                  \"ICAO Destination Airport\", \"Destination City\", \n",
    "                  \"Destination State Code\", \"Destination State Name\"]\n",
    "df[cols_to_string] = df[cols_to_string].astype('string')  # \"string\" can handle NaN unlike \"str\"\n",
    "\n",
    "# Clean city names by removing state codes\n",
    "df[\"Origin City\"] = df[\"Origin City\"].str.split(',').str[0].str.strip().astype('string')\n",
    "df[\"Destination City\"] = df[\"Destination City\"].str.split(',').str[0].str.strip().astype('string')\n",
    "\n",
    "# Convert \"Cancellation Code\" to descriptive text\n",
    "df[\"Cancellation Code\"] = df[\"Cancellation Code\"].replace({\n",
    "    \"A\": \"Carrier\", \n",
    "    \"B\": \"Weather\", \n",
    "    \"C\": \"National Air System\", \n",
    "    \"D\": \"Security\"\n",
    "})\n",
    "\n",
    "# Create \"Status\" column to simplify flight status identification\n",
    "df['Status'] = df.apply(\n",
    "    lambda row: 'D' if row['Diversion Label'] == 1 \n",
    "    else 'C' if row['Cancellation Label'] == 1 \n",
    "    else 'A', axis=1\n",
    ")\n",
    "\n",
    "# Remove redundant status label columns\n",
    "df = df.drop(columns=[\"Diversion Label\", \"Cancellation Label\"])\n",
    "```\n",
    "\n",
    "## 7. Final Dataset and Export\n",
    "\n",
    "```python\n",
    "# Select and organize final columns for the cleaned dataset\n",
    "sorted_features = [\n",
    "    \"Unique Carrier Code\", \"Tail Number\", \n",
    "    \"Origin Airport ID\", \"ICAO Origin Airport\", \"Origin City\", \"Origin State Code\", \"Origin State Name\", \n",
    "    \"Destination Airport ID\", \"ICAO Destination Airport\", \"Destination City\", \"Destination State Code\", \"Destination State Name\", \n",
    "    \"Quarter\", \"Day of Week\", \n",
    "    \"Scheduled Departure Time UTC\", \"Actual Departure Time UTC\", \"Departure ΔT (min)\", \"Departure Delay Label\", \n",
    "    \"Taxi Out Time (min)\", \"Wheels Off Time UTC\", \n",
    "    \"Wheels On Time UTC\", \"Taxi In Time (min)\", \n",
    "    \"Scheduled Arrival Time UTC\", \"Actual Arrival Time UTC\", \"Arrival ΔT (min)\", \"Arrival Delay Label\", \n",
    "    \"Scheduled Elapsed Time (min)\", \"Actual Elapsed Time (min)\", \"Air Time (min)\", \"Distance (miles)\", \n",
    "    \"Status\", \"Cancellation Code\", \"Carrier Delay (min)\", \"Weather Delay (min)\", \n",
    "    \"National Air System Delay (min)\", \"Security Delay (min)\", \"Late Aircraft Delay (min)\"\n",
    "]\n",
    "\n",
    "# Create final dataset with selected features\n",
    "df_utc = df[sorted_features].copy()\n",
    "\n",
    "# Save processed data to pickle file to preserve data types\n",
    "df_utc.to_pickle('./data/preprocessed_data/df_utc.pkl')\n",
    "\n",
    "print(\"Data preprocessing completed successfully!\")\n",
    "```\n",
    "\n",
    "## 8. Data Exploration and Validation (Optional)\n",
    "\n",
    "```python\n",
    "# Display information about the final dataset\n",
    "print(\"\\nFinal dataset information:\")\n",
    "print(f\"Number of flights: {len(df_utc)}\")\n",
    "print(f\"Number of features: {df_utc.shape[1]}\")\n",
    "print(\"\\nData types:\")\n",
    "print(df_utc.dtypes)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(\"\\nMissing values in final dataset:\")\n",
    "missing_values = df_utc.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Display sample of the processed data\n",
    "print(\"\\nSample of processed data:\")\n",
    "display(df_utc.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff3801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "519.156px",
    "left": "92px",
    "top": "111.125px",
    "width": "415.266px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
